#coding:utf-8
import urllib
import urllib2
import sys,time
import os
import random
from bs4 import BeautifulSoup

Headers = {
        'Host':'kr.hujiang.com',
        'Proxy-Connection':'keep-alive',
        'Upgrade-Insecure-Requests':'1',
        'Cache-Control':'private',
        'User-Agent':'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.101 Safari/537.36',
        'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
        'Accept-Language':'zh-CN,zh;q=0.8'}

link_list = []
chn_list = []
kor_list = []

def GetHtml():
   
    a = 1
    while a<= 64:
        print 'page:',a,'processing'
        url = 'http://kr.hujiang.com/new/hanyuxinwen/page{}/'.format(a)
    
        proxy = urllib2.ProxyHandler({'http':'109.105.1.52:8080'})
        opener = urllib2.build_opener(proxy)
        urllib2.install_opener(opener)
        req = urllib2.Request(url,headers = Headers)
        page = urllib2.urlopen(req,timeout = 10)
        html = page.read()
        #print html

        soup = BeautifulSoup(html,from_encoding = 'utf-8')
        article = soup.find('ul',id='article_list').find_all('div',class_='article_list_info')
        #print article

        for item in article:
            page_link = item.h2.find_all('a')[1]['href']
            print page_link
            link = 'http://kr.hujiang.com' + page_link
            kor,chn = GetText(link)
            kor_list.extend(kor)
            chn_list.extend(chn)
            link_list.append(link)
        #a += 1
        print len(kor_list),len(chn_list)
        time.sleep(1*random.random()+1)


def GetText(link):
    
    url = link

    proxy = urllib2.ProxyHandler({'http':'109.105.1.52:8080'})
    opener = urllib2.build_opener(proxy)
    urllib2.install_opener(opener)
    req = urllib2.Request(url,headers = Headers)
    page = urllib2.urlopen(req,timeout = 10)
    html = page.read()
    
    soup = BeautifulSoup(html,from_encoding = 'utf-8')
    kor_l = [e.text for e in soup.find_all('div',class_='langs_en')] 
    chn_l = [e.find_next('div',class_='langs_cn').text for e in soup.find_all('div',class_='langs_en')]
    
    print len(kor_l)==len(chn_l)
    #for item1,item2 in zip(kor_l,chn_l):
        #print item1
        #print item2

    f1 = open('result','a+')
    for item1,item2 in zip(kor_l,chn_l):
        if len(item1) > 8:
                f1.write((item1 + item2 + '\n').encode('utf-8'))
    time.sleep(1*random.random()+1) 
    return kor_l,chn_l

GetHtml()
    
