# -*- coding: utf-8 -*-


import sys
import os
os.chdir(r'D:\yu_xiao_shi\corpus\Naver_back_trans')
import time
import urllib
from urllib import request,parse
from bs4 import BeautifulSoup

def get_sentence(word,page):
    #url open
    word_q=parse.quote(word)
    try:
        url='https://endic.naver.com/search_example.nhn?sLn=kr&ifAjaxCall=true&query={}&searchType=example&fieldType=&txtType=0&langType=0&isTranslatedType=1&degreeType=0&timeType=4&ui=full&pageNo={}'.format(word_q,page)
        req=request.Request(url,headers=Header)
        page_source=request.urlopen(req,timeout=3)
        html=page_source.read().decode('utf-8')
        soup=BeautifulSoup(html,'lxml')
        kor_list=soup.find_all('div',class_='fnt_k10')
        print('page', page, 'total ',len(kor_list), 'kor samples')
        eng_list=soup.find_all('input',type='hidden')
        print('page', page, 'total ',len(eng_list), 'eng samples')
        print('------',len(kor_list)==len(eng_list),'------')
        for kor,eng in zip(kor_list,eng_list):
            user=kor.find('a',class_='user_ts')
            if user is None:
                kor=kor.find('a',class_='N=a:xml.detail').text
                eng=eng['value']
                sentence_dict[eng]=kor 
        return None
    except:
        result=get_sentence(word,page)
        return result



def get_page(word,page):
    #url open
    word_q=parse.quote(word)
    try:
        url='https://endic.naver.com/search_example.nhn?sLn=kr&ifAjaxCall=true&query={}&searchType=example&fieldType=&txtType=0&langType=0&isTranslatedType=1&degreeType=0&timeType=4&ui=full&pageNo={}'.format(word_q,page)
        req=request.Request(url,headers=Header)
        page_source=request.urlopen(req,timeout=3)
        html=page_source.read().decode('utf-8')
        if html[:html.find('||||')]=='0':
            return 0
        else:
            total_count=int(html[:html.find('||||')].replace(',','').replace(' ',''))
            if total_count%20==0:
                total_page=total_count//20
            else:
                total_page=(total_count//20)+1
        soup=BeautifulSoup(html,'lxml')
        kor_list=soup.find_all('div',class_='fnt_k10')
        print('page', page, 'total ',len(kor_list), 'kor samples')
        eng_list=soup.find_all('input',type='hidden')
        print('page', page, 'total ',len(eng_list), 'eng samples')
        print('------',len(kor_list)==len(eng_list),'------')
        for kor,eng in zip(kor_list,eng_list):
            user=kor.find('a',class_='user_ts')
            if user is None:
                kor=kor.find('a',class_='N=a:xml.detail').text
                eng=eng['value']
            #if (word not in kor) and (word.replace(' ','') not in kor):
            #    continue
                sentence_dict[eng]=kor
        return total_page
    except:
        total_page=get_page(word,page)
        return total_page


#add proxy
if __name__=='__main__':
    proxy=request.ProxyHandler({'https':'127.0.0.1:55682'})
    opener=request.build_opener(proxy)
    request.install_opener(opener)
    
    #fill request headers
    Header={'Host':'endic.naver.com',
            'Connection':'keep-alive',
            'Cache-Control':'no-cache',
            'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language':'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2',
            'User-Agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:65.0) Gecko/20100101 Firefox/65.0'
            }
    
    
    #fill the dict
    en_dict=[]
    file=open('en_dict_2',encoding='utf-8')
    for line in file:
        line=line.strip()
        print(line)
        en_dict.append(line)
    
    sentence_dict={}
    while len(en_dict)>0:
        word=en_dict.pop()
        page=1
        total_page=get_page(word,page)
        if total_page==0:
            continue
        print(word,', total page:',total_page)
        time.sleep(1)
        while page<total_page:
            page+=1
            result=get_sentence(word,page)
            time.sleep(0.5)
            if page>300:
                break
        with open('eng_total_sent_2','a',encoding='utf-8') as save:
            for key,value in sentence_dict.items():
                save.write(word+' ||| '+key+' ||| '+value+'\n')
        sentence_dict={}

         







