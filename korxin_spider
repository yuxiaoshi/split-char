#coding:utf-8
import urllib2
import urllib
import time,random
from bs4 import BeautifulSoup

Headers = {
        'Host':'dic.koreaxin.com',
        'Proxy-Connection':'keep-alive',
        'Upgrade-Insecure-Requests':'1',
        'Cache-Control':'max-age=0',
        'User-Agent':'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',
        'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
        'Accept-Language':'zh-CN,zh;q=0.8'}

List = ['가','각','간','갈','감','갑','값','강','갖','같','개','거','걱','건','걷','걸','검','것','게','겨','결','경','계','고','곧','골','곱','곳','공','과','관','광','괜','교','구','국','군','굽','권','귀','규','귤','그','극','근','글','금','급','기','긴','길','김','까','깎','깜','깨','꺼','껌','꼭','꽃','꾸','꿈','끄','끓','끝','끼','나','낚','날','남','낮','내','냄','냉','너','넓','넘','넣','네','넥','넷','년','노','녹','놀','농','높','놓','누','눈','눕','뉴','느','늘','능','늦','님','다','닦','단','닫','달','닭','닮','담','답','당','대','댁','더','덕','덥','덮','데','도','독','돈','돌','돕','동','돼','되','된','두','둘','뒤','드','듣','들','등','디','따','딸','땀','때','떠','떡','떨','또','똑','뛰','뜨','뜻','라','러','로','마','막','만','많','말','맑','맛','맞','매','맥','맵','머','먹','먼','멀','멋','메','멕','며','면','명','몇','모','목','몸','못','몽','무','문','묻','물','뭐','미','민','밀','밑','바','박','밖','반','받','발','밝','밤','밥','방','배','백','버','번','벌','벗','벚','베','벽','변','별','병','보','복','볶','볼','봄','봉','뵙','부','북','분','불','붓','붙','브','블','비','빌','빠','빨','빵','빼','사','산','살','삼','상','새','색','샌','생','샤','샴','서','선','설','섬','성','세','센','셋','소','속','손','송','쇼','수','숙','순','숟','술','쉬','쉰','쉽','슈','스','슬','습','시','식','신','실','싫','심','십','싱','싸','쌀','쌓','썰','쓰','씨','씩','씹','씻','아','악','안','앉','알','앞','액','야','약','얇','양','얘','어','언','얼','엄','없','에','엘','여','역','연','열','엽','영','옆','예','옛','오','올','옮','옷','와','왜','외','왼','요','우','운','울','움','웃','원','월','웬','위','유','육','은','음','응','의','이','인','일','읽','잃','입','있','잊','자','작','잔','잘','잠','잡','장','재','저','적','전','절','젊','점','젓','정','제','조','졸','좀','좁','종','좋','죄','주','죽','준','줄','중','즐','증','지','직','진','질','짐','집','짓','짜','짧','쪽','쯤','찌','찍','차','착','참','창','찾','채','책','처','천','철','첫','청','초','촬','최','추','축','출','춤','춥','취','층','치','친','칠','침','칫','카','칼','캐','커','컴','컵','케','켜','코','콜','콧','콩','크','큰','키','킬','타','탁','태','택','탤','터','테','텔','토','통','퇴','특','틀','티','팀','파','팔','패','펴','편','평','포','표','푹','풀','프','피','필','하','학','한','할','함','합','항','해','핸','햄','햇','행','허','현','형','호','혼','홈','홍','화','확','환','회','횡','후','휴','흐','흰','힘']

word_list = []

def GetHtml(url):
    
    proxy = urllib2.ProxyHandler({'http':'109.105.1.52:8080'})
    opener = urllib2.build_opener(proxy)
    urllib2.install_opener(opener)
    req = urllib2.Request(url,headers = Headers)
    page = urllib2.urlopen(url,timeout = 20)
    html = page.read()
    soup = BeautifulSoup(html,from_encoding='utf-8')
    page = soup.find('div',class_='box').find('tr',class_='gray').td.string
    count = int(page.split(':')[1].strip())
    if count < 20:
        page = 1
    else:
        page = (count/20)+1
    #print page
    return html,page

def spider():

    while len(List) != 0:
        word = List.pop()
        url_word = urllib.quote(word)
        for num in xrange(1,6):
            try:
                url = 'http://dic.koreaxin.com/index.php?a=list&d=35&p={}&w1={}'.format(num,url_word)
                html,page = GetHtml(url)
                soup = BeautifulSoup(html,from_encoding='utf-8')
                for item in soup.find('div',class_='box').find_all('dt',class_='termpreview'):
                    res = item.a.string
                    #print res
                    if (res is not None) and (res not in word_list):
                        word_list.append(res)
                print url,'done!'
            
                if page == 1:
                    break

            except:
                print word,'failed'
                List.insert(0,word)

            time.sleep(1*random.random()+5)

spider()
print len(word_list)
f1 = open('kor_word','w')
for item in word_list:
    f1.write((item + '\n').encode('utf-8'))
        

