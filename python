#!/usr/bin/env python
# -*- coding: UTF-8 -*-

import os, sys
import re, json
import pandas as pd
import numpy as np

def ToJson(fp, wfp):
	reader = open(fp, 'rb')
	names = {0:'URL', 1:'Chinese', 2:'Korean'}
	name_idx = 0
	temp_idx = ''
	total_info = []
	article_info = {}
	for line in reader:
		infos = line.decode('UTF-8').rstrip().split(' ||| ')
		idx = infos[0]
		values = infos[1]
		if temp_idx!=idx:
			if article_info:
				total_info.append(article_info)
			article_info = {}
			name_idx = 0
			temp_idx = idx
		else:
			name_idx += 1
		article_info[names[name_idx]] = values
	total_info.append(article_info)
	reader.close()
	writer = open(wfp, 'wb')
	writer.write(json.dumps(total_info, ensure_ascii = False, indent = 2).encode('UTF-8'))
	writer.close()
	return 0

def ChangeFileFormat():
	dir_path = 'result'
	w_dir_path = 'result_json'
	try:
		os.mkdir(w_dir_path)
	except Exception as e:
		pass
	for file_name in os.listdir(dir_path):
		fp = os.path.join(dir_path, file_name)
		wfp = os.path.join(w_dir_path, file_name.split('.')[0]+'.json')
		ToJson(fp, wfp)

	return 0

def DirtyCleaner(paragraph):
	p_re = re.compile(r'<p.*?>', re.S)
	paragraph = re.sub(p_re, '_start_', paragraph)
	_p_re = re.compile(r'</p>', re.S)
	paragraph = re.sub(_p_re, '_end_', paragraph)
	dirty_re = re.compile(r'<.*?>', re.S)
	paragraph = re.sub(dirty_re, '', paragraph)
	return paragraph

def ExtractJson():
	dir_path = 'data/json'
	total_a, right_a = 0, 0
	total_p, right_p = 0, 0
	ch_dir_path = 'result/20170601/ch'
	try:
		os.mkdir(ch_dir_path)
	except Exception as e:
		pass
	ko_dir_path = 'result/20170601/ko'
	try:
		os.mkdir(ko_dir_path)
	except Exception as e:
		pass
	for file_name in os.listdir(dir_path):
		fp = os.path.join(dir_path, file_name)
		reader = open(fp, 'rb')
		json_data = json.loads(reader.read().decode('UTF-8'))
		reader.close()
		ch_fp = os.path.join(ch_dir_path, file_name.split('.')[0])
		ko_fp = os.path.join(ko_dir_path, file_name.split('.')[0])
		ch_writer = open(ch_fp, 'wb')
		ko_writer = open(ko_fp, 'wb')
		for doc in json_data:
			total_a += 1
			url = doc['URL']
			chinese = doc['Chinese']
			korean = doc['Korean']
			chinese_clean = DirtyCleaner(chinese)
			end_flag = True
			if chinese_clean[-5:]=='_end_':
				chinese_clean =chinese_clean[:-5]
			chinese_split = chinese_clean.split('_end_')
			korean_clean = DirtyCleaner(korean)
			if korean_clean[-5:]=='_end_':
				korean_clean =korean_clean[:-5]
			korean_split = korean_clean.split('_end_')
			if len(chinese_split)==len(korean_split):
				right_a += 1
				chinese_korean = zip(chinese_split, korean_split)
				for ch, ko in chinese_korean:
					total_p += 1
					ch_sents = ch.replace('\n', '').split('。')
					ko_sents = ko.replace('\n', '').split('.')
					if len(ch_sents)==len(ko_sents):
						right_p += 1
						for ch_s, ko_s in zip(ch_sents, ko_sents):
							ch_writer.write((ch_s+'\n').encode('UTF-8'))
							ko_writer.write((ko_s+'\n').encode('UTF-8'))
		ch_writer.close()
		ko_writer.close()
	print('文章总数：{}   中韩段落数量相等文章总数：{}   占比：{}'.format(total_a, right_a, right_a/total_a))
	print('段落总数：{}   中韩句子数量相等段落总数：{}   占比：{}'.format(total_p, right_p, right_p/total_p))

def KoreanTest():
	fp = 'sample.json'
	reader = open(fp, 'rb')
	json_data = json.loads(reader.read().decode('UTF_8'))
	reader.close()
	print(json_data)

def main():
	ExtractJson()
	return 0

if __name__ == '__main__':
	main()
